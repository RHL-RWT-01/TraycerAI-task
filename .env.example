# Environment Configuration
# Copy this file to .env and update the values as needed

# Server Configuration
PORT=3000
NODE_ENV=development

# API Keys
# OpenAI API key for LLM integration
OPENAI_API_KEY=your_openai_api_key_here

# Anthropic API key for Claude integration
ANTHROPIC_API_KEY=your_anthropic_api_key_here

# LLM Configuration
# Default LLM provider to use (openai or anthropic)
DEFAULT_LLM_PROVIDER=openai

# Model configurations (optional, will use defaults if not specified)
OPENAI_MODEL=gpt-4-turbo-preview
ANTHROPIC_MODEL=claude-3-sonnet-20240229

# LLM request settings
LLM_MAX_TOKENS=4096
LLM_TEMPERATURE=0.7
LLM_MAX_RETRIES=3
LLM_RETRY_DELAY=1000

# Logging Configuration
LOG_LEVEL=info